{
  "success": true,
  "target_met": true,
  "total_iterations": 1,
  "best_result": {
    "iteration": 1,
    "quant_level": "q8_0",
    "model_path": "quant_pass1\\models\\Llama-2-13b-chat-hf_quantized_q8_0_iter1",
    "model_size_mb": 16295.840877174069,
    "emotional_metrics": {
      "response_fluency": 0.82,
      "emotional_intensity": 0.604,
      "emotional_match": 0.6731428571428572,
      "empathy_score": 0.556,
      "metaphor_usage": 0.6559999999999999,
      "sentiment_accuracy": 0.7120000000000001
    },
    "quantization_time": 0.0,
    "evaluation_time": 0.0005166530609130859,
    "success": true,
    "error_message": "",
    "overall_score": 0.6708857142857143
  },
  "baseline_score": 0.6708857142857143,
  "final_degradation": 0.0,
  "results": [
    {
      "iteration": 2,
      "quant_level": "q6_K",
      "model_path": "quant_pass1\\models\\Llama-2-13b-chat-hf_quantized_q6_K_iter2",
      "model_size_mb": 13095.839822894563,
      "emotional_metrics": {
        "response_fluency": 0.82,
        "emotional_intensity": 0.604,
        "emotional_match": 0.6731428571428572,
        "empathy_score": 0.556,
        "metaphor_usage": 0.6559999999999999,
        "sentiment_accuracy": 0.7120000000000001
      },
      "quantization_time": 0.0,
      "evaluation_time": 0.0004775524139404297,
      "success": true,
      "error_message": "",
      "overall_score": 0.6708857142857143
    }
  ],
  "timestamp": "2025-07-29T17:51:19.511774"
}